# Automatic scaling of pods and cluster nodes
Kubernetes can monitor your pods and scale them up automatically as soon as it detects an increase in the CPU usage or some other metric.

15.1 Horizontal pod autoscaling

HorizontalPodAutoscaler (HPA) resource
periodically checks pod metrics, calculates the number of replicas required to meet
the target metric value configured in the HorizontalPodAutoscaler resource

15.1.1 Understanding the autoscaling process

OBTAINING POD METRICS
gets the metrics of all the pods by querying Heapster
through REST calls.

A look at changes related to how the Autoscaler obtains metrics
1.6 != 1.7 != 1.9
--horizontal-pod-autoscaler-use-rest-clients=true flag
API server will not expose the metrics itself

CALCULATING THE REQUIRED NUMBER OF PODS

has metrics for all the pods belonging to the resource
sum the metrics for all the pods and outputs an integer with the number of replicas

UPDATING THE DESIRED REPLICA COUNT ON THE SCALED RESOURCE

work without knowing any details of the resource it’s scaling

Scale sub-resource
 Deployments
 ReplicaSets
 ReplicationControllers
 StatefulSets


UNDERSTANDING THE WHOLE AUTOSCALING PROCESS
each component gets the metrics from the other components periodically
takes quite a while for the metrics data to be propagated

15.1.2 Scaling based on CPU utilization

Always set the target CPU usage well below 100% (and definitely never
above 90%) to leave enough room for handling sudden load spikes.

only the pod’s guaranteed CPU amount (the
CPU requests) is important when determining the CPU utilization of a pod.

CREATING A HORIZONTALPODAUTOSCALER BASED ON CPU USAGE

Listing 15.1 Deployment with CPU requests set: deployment.yaml

$ kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5

Always make sure to autoscale Deployments instead of the underlying ReplicaSets.

$ kubectl get hpa.v2beta1.autoscaling kubia -o yaml


SEEING THE FIRST AUTOMATIC RESCALE EVENT
$ kubectl get hpa


Listing 15.3 Inspecting a HorizontalPodAutoscaler with kubectl describe
$ kubectl describe hpa

TRIGGERING A SCALE-UP
kubectl expose deployment kubia --port=80 --target-port=8080

Listing 15.4 Watching multiple resources in parallel

$ watch -n 1 kubectl get hpa,deployment

$ kubectl run -it --rm --restart=Never loadgenerator --image=busybox -- sh -c "while true; do wget -O - -q http://kubia.default; done"

SEEING THE AUTOSCALER SCALE UP THE DEPLOYMENT

kubectl describe

UNDERSTANDING THE MAXIMUM RATE OF SCALING
The autoscaler will at most double the number of replicas in a single operation
has a limit on how soon a subsequent autoscale operation

a scale-up will occur only if no rescaling event occurred in the last three minutes.
scale-down event is performed every five minutes

MODIFYING THE TARGET METRIC VALUE ON AN EXISTING HPA OBJECT

change the targetAverageUtilization field to 60
Listing 15.6 Increasing the target CPU utilization by editing the HPA resource

after you modify the resource, your changes will be detected by the autoscaler controller and acted upon

15.1.3 Scaling based on memory consumption
Memory-based autoscaling is much more problematic than CPU-based autoscaling
releasing memory depends on the application. 

15.1.4 Scaling based on other and custom metrics
http://medium.com/@marko.luksa.

the metrics field allows you to define more than one metric to use
Resource
Pods
Object

UNDERSTANDING THE RESOURCE METRIC TYPE

PODS METRIC TYPE
Queries- Per-Second (QPS) or the number of messages in a message broker’s queue

type: Pods
resource:
metricName: qps
targetAverageValue: 100

UNDERSTANDING THE OBJECT METRIC TYPE

type: Object
The name of
resource:
the metric
metricName: latencyMillis
target:
apiVersion: extensions/v1beta1
The specific object whose metric
kind: Ingress
the autoscaler should obtain
name: frontend
targetValue: 20

15.1.5 Determining which metrics are appropriate for autoscaling

autoscaler won’t function properly if increasing
the number of replicas doesn’t result in a linear decrease of the average value of the
observed metric

15.1.6 Scaling down to zero replicas
horizontal pod autoscaler currently doesn’t allow setting the minReplicas field to 0

Kubernetes currently doesn’t provide this feature yet, but it will eventually. Check
the documentation to see if idling has been implemented yet.

15.2 Vertical pod autoscaling

currently not possible to change either resource requests
or limits of existing pods

Please refer to the Kubernetes documentation to find out whether vertical pod autoscaling is already implemented or not.

15.3 Horizontal scaling of cluster nodes
Kubernetes includes the feature to automatically request additional nodes from
the cloud provider

15.3.1 Introducing the Cluster Autoscaler
The Cluster Autoscaler takes care of automatically provisioning additional nodes
when it notices a pod that can’t be scheduled to existing nodes because of a lack of
resources on those nodes. It also de-provisions nodes when they’re underutilized for
longer periods of time.

REQUESTING ADDITIONAL NODES FROM THE CLOUD INFRASTRUCTURE
Cloud providers usually group nodes into groups
Cluster Autoscaler does this by examining the available node groups

RELINQUISHING NODES
The Cluster Autoscaler also needs to scale down the number of nodes when they
aren’t being utilized enough

If the CPU and memory requests of all the pods
running on a given node are below 50%, the node is considered unnecessary
If a system pod is running on a node, the node won’t be relinquished.
a node will only be returned to the cloud provider if the Cluster Autoscaler
knows the pods running on the node will be rescheduled to other nodes

15.3.2 Enabling the Cluster Autoscaler

Google Kubernetes Engine (GKE)
Google Compute Engine (GCE)
Amazon Web Services (AWS)
Microsoft Azure

Refer to the Cluster Autoscaler GitHub repo at https://github.com/kubernetes/auto-
scaler/tree/master/cluster-autoscaler for information on how to enable it on other
platforms.

15.3.3 Limiting service disruption during cluster scale-down
PodDisruptionBudget resource

contains only a pod label selector and a number
specifying the minimum number of pods that must always be available

$ kubectl create pdb kubia-pdb --selector=app=kubia --min-available=3

$ kubectl get pdb kubia-pdb -o yaml
